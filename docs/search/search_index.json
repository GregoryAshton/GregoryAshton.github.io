{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Dr Gregory Ashton About me I am a Research Fellow in the Institute for Cosmology and Gravitation (ICG) at the University of Portsmouth. My interest is the relativistic astrophysics of neutron stars and black holes and I am a member of the LIGO Scientific Collaboration . In 2016, I completed my PhD Timing variations in neutron stars: models, inference and their implications for gravitational waves at the University of Southampton under the joint supervision of Prof. David Ian Jones and Dr. Reinhard Prix (Albert Einstein Institute, Hannover). I then worked as a Postdoc in Hannover with Reinhard and others in the Continuous Gravitational Wave group , before moving to Melbourne to work with Paul Lasky in Monash University (Melbourne Australia). In 2020, I moved back to the UK to teach foundation year maths at Royal Holloway before moving to the ICG to work with Dr Laura Nutall . Contact: gregory.ashton@ligo.org My CV My list of publications ADS library News 26/Oct/2021 A paper led by the ICG's Simone Mozzon Does non-stationary noise in LIGO and Virgo affect the estimation of H0? hit the arXiv today. 07/Oct/2021 New paper day! Parameterised population models of transient non-Gaussian noise in the LIGO gravitational-wave detectors . This work has taken nearly 2 years from the initial conception, a huge amount of computing, and lots of thinking. I really enjoyed getting into a new aspect of GW astronomy, namely the characterisation of the detector. 17/Sep/2021 My daughter Ada was born at 4am. Very happy, excited, and tired! 29/Jul/2021 New paper led by PhD student Avi Vajpeyi on A search for intermediate-mass black holes mergers in the second LIGO--Virgo observing run with the Bayes Coherence Ratio 14/Jul/2021 Today I helped out in Royal Holloway's Girls into Physics program run by the Small Piece trust where we did Python programming for science 29/Jun/2021 The LVK collaboration published Observation of gravitational waves from two neutron star-black hole coalescences in ApJL. This was a really fun project to be involved in. That we can make a definitive statement about the nature of the secondary (light-mass) object with a counterpart is testament to our understanding of controlling systematic uncertainty. 17/Jun/2021 We released a new paper: Bilby-MCMC: An MCMC sampler for gravitational-wave inference . This was really fun as I got to write a sampler from scratch and remind myself of all the gory details. 16/Jun/2021 I helped out with the Royal Holloway Particle Physics Masterclass introducing python programming. 11/May/2021 New paper with PhD student Zhi-Qiang You: Optimized localization for gravitational-waves from merging binaries submitted to MNRAS. 10/May/2021 The Gravitational Wave Open Data Workshop #4 kicked off today on gather.town . 12/Apr/2021 Today I was elected as co-chair of the LIGO collaboration Compact Binary Coalescence (CBC) group. I join Chad Hanna and Walter Del Pozzo and look forward to helping coordinate the discovery and analysis of signals from colliding black holes and neutron stars. 08/Apr/2021 Today I'm taking part in Royal Holloway's Astrophysics Residential for 2021. I'm covering an introduction to programming and how to calculate Pi using random numbers . 12/Mar/2021 My students successfully nominated me for a You\u2019re Valued Award at Royal Holloway . I'm proud to add some of their comments here: \u201cGreg is an amazing teacher. His enthusiastic approach to teaching maths to us foundation year students has made us enthusiastic as well. he is very friendly and approachable and when we need help he very patiently helps explain everything to us. He is dedicated to make us understand all the concepts he teaches and help us learn to our best capacity.\u201d and \u201cGreg always focuses on our individual worries and makes sure we understand before moving on. He's very good at teaching and we're happy to have him as our maths professor :)\u201d. 08/Feb/2021 I presented Flickering of the Vela pulsar to the CAMK journal club. 28/Jan/2021 My PhD student Nikhil Sarin passed his pre-submission milestone. It has been a pleasure to watch Nik develop into a great researcher - his next employer will be lucky to have him. 27/Jan/2021 New paper on arXiv! Work led by David Keitel \"PyFstat: a Python package for continuous gravitational-wave data analysis\" which updates the latest on the PyFstat package for Continuous-Wave analyses. 14/Jan/2021 New paper! Work led by Eric Burns \"Identification of a Local Sample of Gamma-Ray Bursts Consistent with a Magnetar Giant Flare Origin\" hits the arXiv. 11/Jan/2021 Semester 2 gets underway at RHUL. I'm teaching FY1006 Mathematics II to 140 students in online mode for the foreseable future. 07/Jan/2021 I gave a talk titled \"The deepening mystery of the Vela radio-pulsar glitch\" at the Department of Physics, Bar-Ilan University on our recent Vela paper. 04/Dec/2020 I gave an improptu talk to the University of Southampton's astrophysics group on our recent Vela paper. 16/Nov/2020 New paper \"Flickering of the Vela pulsar during its 2016 glitch\" on the arXiv. 10/Nov/2020 I was awarded the 2020 USERN Physical and Chemical Sciences prize . 04/Nov/2020 I gave a presentation to Royal Holloway's Physics group \"Turning Wiggles into Science\" Gallery","title":"Home"},{"location":"#dr-gregory-ashton","text":"","title":"Dr Gregory Ashton"},{"location":"#about-me","text":"I am a Research Fellow in the Institute for Cosmology and Gravitation (ICG) at the University of Portsmouth. My interest is the relativistic astrophysics of neutron stars and black holes and I am a member of the LIGO Scientific Collaboration . In 2016, I completed my PhD Timing variations in neutron stars: models, inference and their implications for gravitational waves at the University of Southampton under the joint supervision of Prof. David Ian Jones and Dr. Reinhard Prix (Albert Einstein Institute, Hannover). I then worked as a Postdoc in Hannover with Reinhard and others in the Continuous Gravitational Wave group , before moving to Melbourne to work with Paul Lasky in Monash University (Melbourne Australia). In 2020, I moved back to the UK to teach foundation year maths at Royal Holloway before moving to the ICG to work with Dr Laura Nutall . Contact: gregory.ashton@ligo.org My CV My list of publications ADS library","title":"About me"},{"location":"#news","text":"26/Oct/2021 A paper led by the ICG's Simone Mozzon Does non-stationary noise in LIGO and Virgo affect the estimation of H0? hit the arXiv today. 07/Oct/2021 New paper day! Parameterised population models of transient non-Gaussian noise in the LIGO gravitational-wave detectors . This work has taken nearly 2 years from the initial conception, a huge amount of computing, and lots of thinking. I really enjoyed getting into a new aspect of GW astronomy, namely the characterisation of the detector. 17/Sep/2021 My daughter Ada was born at 4am. Very happy, excited, and tired! 29/Jul/2021 New paper led by PhD student Avi Vajpeyi on A search for intermediate-mass black holes mergers in the second LIGO--Virgo observing run with the Bayes Coherence Ratio 14/Jul/2021 Today I helped out in Royal Holloway's Girls into Physics program run by the Small Piece trust where we did Python programming for science 29/Jun/2021 The LVK collaboration published Observation of gravitational waves from two neutron star-black hole coalescences in ApJL. This was a really fun project to be involved in. That we can make a definitive statement about the nature of the secondary (light-mass) object with a counterpart is testament to our understanding of controlling systematic uncertainty. 17/Jun/2021 We released a new paper: Bilby-MCMC: An MCMC sampler for gravitational-wave inference . This was really fun as I got to write a sampler from scratch and remind myself of all the gory details. 16/Jun/2021 I helped out with the Royal Holloway Particle Physics Masterclass introducing python programming. 11/May/2021 New paper with PhD student Zhi-Qiang You: Optimized localization for gravitational-waves from merging binaries submitted to MNRAS. 10/May/2021 The Gravitational Wave Open Data Workshop #4 kicked off today on gather.town . 12/Apr/2021 Today I was elected as co-chair of the LIGO collaboration Compact Binary Coalescence (CBC) group. I join Chad Hanna and Walter Del Pozzo and look forward to helping coordinate the discovery and analysis of signals from colliding black holes and neutron stars. 08/Apr/2021 Today I'm taking part in Royal Holloway's Astrophysics Residential for 2021. I'm covering an introduction to programming and how to calculate Pi using random numbers . 12/Mar/2021 My students successfully nominated me for a You\u2019re Valued Award at Royal Holloway . I'm proud to add some of their comments here: \u201cGreg is an amazing teacher. His enthusiastic approach to teaching maths to us foundation year students has made us enthusiastic as well. he is very friendly and approachable and when we need help he very patiently helps explain everything to us. He is dedicated to make us understand all the concepts he teaches and help us learn to our best capacity.\u201d and \u201cGreg always focuses on our individual worries and makes sure we understand before moving on. He's very good at teaching and we're happy to have him as our maths professor :)\u201d. 08/Feb/2021 I presented Flickering of the Vela pulsar to the CAMK journal club. 28/Jan/2021 My PhD student Nikhil Sarin passed his pre-submission milestone. It has been a pleasure to watch Nik develop into a great researcher - his next employer will be lucky to have him. 27/Jan/2021 New paper on arXiv! Work led by David Keitel \"PyFstat: a Python package for continuous gravitational-wave data analysis\" which updates the latest on the PyFstat package for Continuous-Wave analyses. 14/Jan/2021 New paper! Work led by Eric Burns \"Identification of a Local Sample of Gamma-Ray Bursts Consistent with a Magnetar Giant Flare Origin\" hits the arXiv. 11/Jan/2021 Semester 2 gets underway at RHUL. I'm teaching FY1006 Mathematics II to 140 students in online mode for the foreseable future. 07/Jan/2021 I gave a talk titled \"The deepening mystery of the Vela radio-pulsar glitch\" at the Department of Physics, Bar-Ilan University on our recent Vela paper. 04/Dec/2020 I gave an improptu talk to the University of Southampton's astrophysics group on our recent Vela paper. 16/Nov/2020 New paper \"Flickering of the Vela pulsar during its 2016 glitch\" on the arXiv. 10/Nov/2020 I was awarded the 2020 USERN Physical and Chemical Sciences prize . 04/Nov/2020 I gave a presentation to Royal Holloway's Physics group \"Turning Wiggles into Science\"","title":"News"},{"location":"#gallery","text":"","title":"Gallery"},{"location":"help/","text":"Help This page contains some helpful hints and tips that I've leared through my career. I don't claim these to be perfect solutions, you have suggestions, please feel free to email me. Writing a paper/document Writing scientific papers is a central part of life as a scientist. Like most things, investing a bit of time/money can make the process a little easier and allow you to focus on writing rather than the boring admin that inevitably goes with it. Here are a few ad-hoc things I've picked up which may help: Choose your medium . There are many ways to write a paper. You can use latex directly on your computer (i.e. write a .tex file and compile it with pdflatex ); you can use cloud-based latex solutions like Overleaf (see below); or you could use Word/Google Docs. All of these are great and have their place. Personally, I use latex directly when I'm working on a paper with more than 10 contributors and we need to use git to track changes and merges. I use Overleaf for most papers I write, and I use Word/Google Docs for pretty much anything which does not required images or equations. Use the tools . There are a number of tools which can simplify your life. Taking the pain out of compilling latex, to automatically identifying and fixing spelling, gramatical, and typographic errors. As someone who has some mild dyslexia (and did not pay enough attention at school), I've found these invaluable. Given the availability of the checkers (most are free), it demonstrates real laziness to submit journal articles with typos (something I have definitely done). Here are my favourits: Overleaf : this is a cloud-based latex editor/compiler. For projects where you have a handful of collaborators, the free version works great! Make sure to use the built-in spelling correction. Overlead has an incredible ability to ignore Latex errors and still produce output. This is really useful during the the writing stage. But please, for the love of all that is good in this world, fix those errors eventually . They will result in broken arXiv compillations and usually many some aspect of your document is missing. Grammarly : there is a paid version which provides more in-depthanalysis. In my mind this is worth every penny if you are submitting grants/fellowships where a single typo could upset a reviewer (they are fickle beasts). But, the free version is also great. You can use this for Email, Word documents, and Overleaf (see this S/O page ). codespell : this is great for when you are forced to work on a latex document without overleaf. Use latex macros for results : If your paper contains results from any sort of data analysis, it is likely you'll need to communicate some numbers (e.g. the mass of a star). Please, save yourself much heartache, do not hardcode those numbers into the paper. Instead, create a macro: \\newcommand{\\massofstar}{32.5} then anywhere you refer to the mass, you simply write \\massofstar . Better yet, have your analysis script write the newcommand lines for you in a file macros.tex , then add \\include{macros} in your latex document. Now, when you inevitably find a bug in your code the day before submission, you simply rerun and replace macos.tex . This also allows you to diff between the new and old macros.tex to see what changed! Finally, avoid editing the macros by hand. If you need to round the numbers, do this in the analysis script (this usually takes some thinking, but the uncertainties package can help here). Use latex macros for everything : Another common headache the day before submission is that you realise you have used \\theta to mean to different things. Doh! Or, perhaps your collaborator doesn't like you calling the dimensionaless spin of the black hole \\chi and prefers a_1 . To avoid the dangers of a last-minute Ctrl+F and replace, when you start writing never use symboles directly unless your are super super confident they will not change. Instead, define macros like \\newcommand{\\dimensionalspinmaginitude}{a_1} Being verbose is good here: it means you and your collaborators know that you mean the dimensionless spin magnitude, and not something else! You can also do this for things like software names where the formatting is usually journal specific. Add macros like \\newcommand{\\bilby}{\\textsc{Bilby}} Then when you realise the journal prefers texttt , you change one thing. Organise your bibtex files . Pick a convention for the keys (I like AUTHOR_YEAR , but oftentimes people like to use the ADS/Inspire key) and stick with it. This avoids repeated entries. You can use online tools like this to tidy up a messy bib file. Both NASA ADS and InspireHEP have nice utilisies to generate bibtex files (see, e.g. here and click cite here ). They also allow you to pick the format as well. Personally, I'm not a fan of maintaining a single huge bib file: I write a new one for each paper. Learn some grammar : Honestly, I could not of cared less about grammar while at school. Only during my final year as an undergraduate, when we had to write a 10-page report, I realised that actually, communicating what I had learned was maybe a little bit important. While Grammarly and other tools can help, it is good to learn why they are making changes. Equally, if you have a collaborator who edits the text, ask them why and don't be ashamed. Better to learn later than never. Be consistent in your style : English is a flexible language, but when reading a scientific article, a consistent style of writing avoids distracting the reader. For me, I found \"The Elements of Style\" by Strunk and White to be hugely useful. I don't agree with all of it, but I find it useful to have a single point of reference to consult when I'm unsure. I don't always follow the advice (often you need the passive voice), but I try to maintain it on the whole. There is also an automated checker in perl which you can use to identify problem areas. My script/job/test is not working, what should I do? This is a very common problem. For anyone involved in scientific research which relies on an element of programming, you will no doubt find that, at some point you are faced with a situation where \"it isn't doing what it should be!\" or \"it won't run!\". For those of us, like me, who did not receive formal training on software development, this can be daunting. Your supervisor or colleagues may expect you to solve it without help, what do you do? It might be tempting to either give up or ask for someone else to fix it. But, before you do either of things try to work through this list of steps: Breath : it can be frustrating so first things first, try to take a step back. Grab a cup of tea/coffee/water and let your head clear. Read : now, try reading both your script and the error message (in Python, this is called the TraceBack ). The output messages might be quite long, but try scanning through it and find: Which line of your script causes the error? What is it trying to do? What is the error message (if any) from the output? Does it tell you which program caused the issue? You may find this guide useful in understanding the TraceBack Check : Now check out what else is going on: How long does it take to fail, does it take a long time to fail or straight away? What else is happening with your computer at the time? Does the memory/CPU usage of the program spike? If your script relies on software, what version are you using? Is it up to date, did you update it recently? Have you backed up your script, can you roll back to an earlier version to see if it works? Investigate: hopefully by reading the scripts and logs, you might have an inkling about what is going on. Try to test it out, perhaps remove the line that is failing. What happens? Do you get a new error message? The goal here is to build some intuition about what the error is and the cause. Research: Now that you have an idea about what is going on, it is time to research. A few places that are worth searching: Google/StackOverflow : An easy first step is to simple search the error message on the internet. But, be warned: copy and pasting solutions is usually a recipe for disaster. Instead, read the solutions and comments to help you understand how they solve the problem. Documentation : If the problem seems to be in a specific piece of software, try to find the documentation and scan it. Do they have a guide on troubleshooting, a place where they welcome questions? Source code : If you have identified which line is failing in any underlying software, find the source code (if it is open source). Read it over. It may well be that you have found a bug: this is a great oppotunity to contribute. If you can see how to fix it, try editing the source code, this may require you to install the software from the source code to test your fix. If your fix is successful, consider opening a Merge Request/Pull Request to fix the code. Identify who you will ask for help : If you have run through the steps above and things are still not working, you are now ready to ask for help. First, you need to identify who you will ask If the problem is in a specific piece of software, does that software have a guide for getting help? If you are working with a colleague/supervisor, they may be the right persont to contact now. If your questions are more general, try StackOverflow or look for local programming support groups (e.g. at your University). Ask for help: Now you know who to contact, you should write a message to them. Keep in mind the following: Keep it concise. Avoid long paragraphs and lots of background, focus on what they need to know to help you. Include a Minimum Working Example . This will help them reproduce your problem. In making it you may even solve the problem yourself! Include a description of your investigation and research: they will need to know all the details (i.e. versions of software, any oddities) Tell them what you have tried already. This will make sure they don't repeat the same investigations you have undertaken and help them to help you. If relevant, tell them why you are contacting them. If they have offered support, thank them for it! In some cases, what may appear to be a \"missing feature\" is in fact a large research project. If you need this feature, you may consider offering them an acknowledgement or even co-authorship on any subsequent publications. After all of this, send your message. Have some patience, they may be overwhelmed by other tasks when you email. Feel free to email them again after a week or so if you haven't got an answer. They may have simply forgotten! Getting started in the LIGO Collaboration There is a guide to getting started in the Collaboration, you can find this here . This contains a wealth of information. Here, I'm just listing a few other things I find useful. If you use the Google chrome browser, you can use a Profile associated with your LIGO account. This creates a separate browser window which, by default, logs in to things with your LIGO credentials. This greatly reduced the amount of clicking between different Google logins I have to do when following links. Want to email someone in the collaboration, but not sure of their address? You can head to https://contacts.google.com/ and log in with your LIGO Credentials. This will provide you with all the albert.einstein@ligo.org addresses. With this, you can download it as a CSV and upload it to your email client. Now you have all of LIGO on tab completion!","title":"Help"},{"location":"help/#help","text":"This page contains some helpful hints and tips that I've leared through my career. I don't claim these to be perfect solutions, you have suggestions, please feel free to email me.","title":"Help"},{"location":"help/#writing-a-paperdocument","text":"Writing scientific papers is a central part of life as a scientist. Like most things, investing a bit of time/money can make the process a little easier and allow you to focus on writing rather than the boring admin that inevitably goes with it. Here are a few ad-hoc things I've picked up which may help: Choose your medium . There are many ways to write a paper. You can use latex directly on your computer (i.e. write a .tex file and compile it with pdflatex ); you can use cloud-based latex solutions like Overleaf (see below); or you could use Word/Google Docs. All of these are great and have their place. Personally, I use latex directly when I'm working on a paper with more than 10 contributors and we need to use git to track changes and merges. I use Overleaf for most papers I write, and I use Word/Google Docs for pretty much anything which does not required images or equations. Use the tools . There are a number of tools which can simplify your life. Taking the pain out of compilling latex, to automatically identifying and fixing spelling, gramatical, and typographic errors. As someone who has some mild dyslexia (and did not pay enough attention at school), I've found these invaluable. Given the availability of the checkers (most are free), it demonstrates real laziness to submit journal articles with typos (something I have definitely done). Here are my favourits: Overleaf : this is a cloud-based latex editor/compiler. For projects where you have a handful of collaborators, the free version works great! Make sure to use the built-in spelling correction. Overlead has an incredible ability to ignore Latex errors and still produce output. This is really useful during the the writing stage. But please, for the love of all that is good in this world, fix those errors eventually . They will result in broken arXiv compillations and usually many some aspect of your document is missing. Grammarly : there is a paid version which provides more in-depthanalysis. In my mind this is worth every penny if you are submitting grants/fellowships where a single typo could upset a reviewer (they are fickle beasts). But, the free version is also great. You can use this for Email, Word documents, and Overleaf (see this S/O page ). codespell : this is great for when you are forced to work on a latex document without overleaf. Use latex macros for results : If your paper contains results from any sort of data analysis, it is likely you'll need to communicate some numbers (e.g. the mass of a star). Please, save yourself much heartache, do not hardcode those numbers into the paper. Instead, create a macro: \\newcommand{\\massofstar}{32.5} then anywhere you refer to the mass, you simply write \\massofstar . Better yet, have your analysis script write the newcommand lines for you in a file macros.tex , then add \\include{macros} in your latex document. Now, when you inevitably find a bug in your code the day before submission, you simply rerun and replace macos.tex . This also allows you to diff between the new and old macros.tex to see what changed! Finally, avoid editing the macros by hand. If you need to round the numbers, do this in the analysis script (this usually takes some thinking, but the uncertainties package can help here). Use latex macros for everything : Another common headache the day before submission is that you realise you have used \\theta to mean to different things. Doh! Or, perhaps your collaborator doesn't like you calling the dimensionaless spin of the black hole \\chi and prefers a_1 . To avoid the dangers of a last-minute Ctrl+F and replace, when you start writing never use symboles directly unless your are super super confident they will not change. Instead, define macros like \\newcommand{\\dimensionalspinmaginitude}{a_1} Being verbose is good here: it means you and your collaborators know that you mean the dimensionless spin magnitude, and not something else! You can also do this for things like software names where the formatting is usually journal specific. Add macros like \\newcommand{\\bilby}{\\textsc{Bilby}} Then when you realise the journal prefers texttt , you change one thing. Organise your bibtex files . Pick a convention for the keys (I like AUTHOR_YEAR , but oftentimes people like to use the ADS/Inspire key) and stick with it. This avoids repeated entries. You can use online tools like this to tidy up a messy bib file. Both NASA ADS and InspireHEP have nice utilisies to generate bibtex files (see, e.g. here and click cite here ). They also allow you to pick the format as well. Personally, I'm not a fan of maintaining a single huge bib file: I write a new one for each paper. Learn some grammar : Honestly, I could not of cared less about grammar while at school. Only during my final year as an undergraduate, when we had to write a 10-page report, I realised that actually, communicating what I had learned was maybe a little bit important. While Grammarly and other tools can help, it is good to learn why they are making changes. Equally, if you have a collaborator who edits the text, ask them why and don't be ashamed. Better to learn later than never. Be consistent in your style : English is a flexible language, but when reading a scientific article, a consistent style of writing avoids distracting the reader. For me, I found \"The Elements of Style\" by Strunk and White to be hugely useful. I don't agree with all of it, but I find it useful to have a single point of reference to consult when I'm unsure. I don't always follow the advice (often you need the passive voice), but I try to maintain it on the whole. There is also an automated checker in perl which you can use to identify problem areas.","title":"Writing a paper/document"},{"location":"help/#my-scriptjobtest-is-not-working-what-should-i-do","text":"This is a very common problem. For anyone involved in scientific research which relies on an element of programming, you will no doubt find that, at some point you are faced with a situation where \"it isn't doing what it should be!\" or \"it won't run!\". For those of us, like me, who did not receive formal training on software development, this can be daunting. Your supervisor or colleagues may expect you to solve it without help, what do you do? It might be tempting to either give up or ask for someone else to fix it. But, before you do either of things try to work through this list of steps: Breath : it can be frustrating so first things first, try to take a step back. Grab a cup of tea/coffee/water and let your head clear. Read : now, try reading both your script and the error message (in Python, this is called the TraceBack ). The output messages might be quite long, but try scanning through it and find: Which line of your script causes the error? What is it trying to do? What is the error message (if any) from the output? Does it tell you which program caused the issue? You may find this guide useful in understanding the TraceBack Check : Now check out what else is going on: How long does it take to fail, does it take a long time to fail or straight away? What else is happening with your computer at the time? Does the memory/CPU usage of the program spike? If your script relies on software, what version are you using? Is it up to date, did you update it recently? Have you backed up your script, can you roll back to an earlier version to see if it works? Investigate: hopefully by reading the scripts and logs, you might have an inkling about what is going on. Try to test it out, perhaps remove the line that is failing. What happens? Do you get a new error message? The goal here is to build some intuition about what the error is and the cause. Research: Now that you have an idea about what is going on, it is time to research. A few places that are worth searching: Google/StackOverflow : An easy first step is to simple search the error message on the internet. But, be warned: copy and pasting solutions is usually a recipe for disaster. Instead, read the solutions and comments to help you understand how they solve the problem. Documentation : If the problem seems to be in a specific piece of software, try to find the documentation and scan it. Do they have a guide on troubleshooting, a place where they welcome questions? Source code : If you have identified which line is failing in any underlying software, find the source code (if it is open source). Read it over. It may well be that you have found a bug: this is a great oppotunity to contribute. If you can see how to fix it, try editing the source code, this may require you to install the software from the source code to test your fix. If your fix is successful, consider opening a Merge Request/Pull Request to fix the code. Identify who you will ask for help : If you have run through the steps above and things are still not working, you are now ready to ask for help. First, you need to identify who you will ask If the problem is in a specific piece of software, does that software have a guide for getting help? If you are working with a colleague/supervisor, they may be the right persont to contact now. If your questions are more general, try StackOverflow or look for local programming support groups (e.g. at your University). Ask for help: Now you know who to contact, you should write a message to them. Keep in mind the following: Keep it concise. Avoid long paragraphs and lots of background, focus on what they need to know to help you. Include a Minimum Working Example . This will help them reproduce your problem. In making it you may even solve the problem yourself! Include a description of your investigation and research: they will need to know all the details (i.e. versions of software, any oddities) Tell them what you have tried already. This will make sure they don't repeat the same investigations you have undertaken and help them to help you. If relevant, tell them why you are contacting them. If they have offered support, thank them for it! In some cases, what may appear to be a \"missing feature\" is in fact a large research project. If you need this feature, you may consider offering them an acknowledgement or even co-authorship on any subsequent publications. After all of this, send your message. Have some patience, they may be overwhelmed by other tasks when you email. Feel free to email them again after a week or so if you haven't got an answer. They may have simply forgotten!","title":"My script/job/test is not working, what should I do?"},{"location":"help/#getting-started-in-the-ligo-collaboration","text":"There is a guide to getting started in the Collaboration, you can find this here . This contains a wealth of information. Here, I'm just listing a few other things I find useful. If you use the Google chrome browser, you can use a Profile associated with your LIGO account. This creates a separate browser window which, by default, logs in to things with your LIGO credentials. This greatly reduced the amount of clicking between different Google logins I have to do when following links. Want to email someone in the collaboration, but not sure of their address? You can head to https://contacts.google.com/ and log in with your LIGO Credentials. This will provide you with all the albert.einstein@ligo.org addresses. With this, you can download it as a CSV and upload it to your email client. Now you have all of LIGO on tab completion!","title":"Getting started in the LIGO Collaboration"},{"location":"notes/","text":"Notes Derivations Drawing samples from the Goodman & Weare (2010) proposal distribution Old notes 11/Feb/20: Understanding PP plots 27/Mar/19: Importance Reweighting Example 08/Oct/19: Chirp time bounds","title":"Notes"},{"location":"notes/#notes","text":"","title":"Notes"},{"location":"notes/#derivations","text":"Drawing samples from the Goodman & Weare (2010) proposal distribution","title":"Derivations"},{"location":"notes/#old-notes","text":"11/Feb/20: Understanding PP plots 27/Mar/19: Importance Reweighting Example 08/Oct/19: Chirp time bounds","title":"Old notes"},{"location":"projects/","text":"Projects In this page, I collect various miscellaneous coding projects I have been involved in. Python for Science A set of workbooks to introduce python for scientific programming koala_html A package to quickly create html pages from collections of images kookaburra A python package for profile-domain timing of radio pulsars parallel_bilby A python package to leverage slurm-based HPC clusters. Enables scaling inference jobs up to many hundreds of cores. bilby_pipe A python package for automating the job of running multiple jobs on LIGO Data Grid clusters. bilby A python package providing a user friendly interface to perform parameter estimation. It is primarily designed and built for inference of compact binary coalescence events in interferometric data, but it can also be used for more general problems. PyFstat A python package containing various methods to run continuous gravitational wave searches. Includes glitch-robust, MCMC-based, and transient work. Bayes Bimodal Test A simple python module using the emcee MCMC software to perform a Bayesian model comparison of bimodality. GitCheck : A python appindicator which provides a visual check of the status of git repos. This builds on some of the functionality of batchgit by Max Hebditch. GetTrainTimes : a command-line tool to quickly get train times from the national rail (UK) website. pyweather : a command-line tool to quickly get a visual (ASCII) forecast of the weather for (almost) any location. Using the Google maps API to study average driving speeds around the globe . To see the results have a look here Printing latex elements : This isn't so much a project as a useful script. Often in cleaning up latex docs I trawl through the document searching for occurances of say includegraphics . This script will simply print the elements (for example in \\label{eqn: an equation} the element would be eqn: an equation ) to the command line. It takes multiple files and if unspecified will search for proper tex files to use. It has default flags of -f to find figures and -l to find labels, but you can specify whatever you want with -o . For example $ print_tex_elements somearticle.tex -o cite might for example produce Einstein1916 Newton1675","title":"Projects"},{"location":"projects/#projects","text":"In this page, I collect various miscellaneous coding projects I have been involved in. Python for Science A set of workbooks to introduce python for scientific programming koala_html A package to quickly create html pages from collections of images kookaburra A python package for profile-domain timing of radio pulsars parallel_bilby A python package to leverage slurm-based HPC clusters. Enables scaling inference jobs up to many hundreds of cores. bilby_pipe A python package for automating the job of running multiple jobs on LIGO Data Grid clusters. bilby A python package providing a user friendly interface to perform parameter estimation. It is primarily designed and built for inference of compact binary coalescence events in interferometric data, but it can also be used for more general problems. PyFstat A python package containing various methods to run continuous gravitational wave searches. Includes glitch-robust, MCMC-based, and transient work. Bayes Bimodal Test A simple python module using the emcee MCMC software to perform a Bayesian model comparison of bimodality. GitCheck : A python appindicator which provides a visual check of the status of git repos. This builds on some of the functionality of batchgit by Max Hebditch. GetTrainTimes : a command-line tool to quickly get train times from the national rail (UK) website. pyweather : a command-line tool to quickly get a visual (ASCII) forecast of the weather for (almost) any location. Using the Google maps API to study average driving speeds around the globe . To see the results have a look here Printing latex elements : This isn't so much a project as a useful script. Often in cleaning up latex docs I trawl through the document searching for occurances of say includegraphics . This script will simply print the elements (for example in \\label{eqn: an equation} the element would be eqn: an equation ) to the command line. It takes multiple files and if unspecified will search for proper tex files to use. It has default flags of -f to find figures and -l to find labels, but you can specify whatever you want with -o . For example $ print_tex_elements somearticle.tex -o cite might for example produce Einstein1916 Newton1675","title":"Projects"},{"location":"science/","text":"Science Publications I maintain an ADS library of my publications in addition to the following list. Vajpeyi, Avi, et al A search for intermediate-mass black holes mergers in the second LIGO--Virgo observing run with the Bayes Coherence Ratio Ashton, Gregory; Talbot, Colm Bilby-MCMC: An MCMC sampler for gravitational-wave inference Keitel, David; Tenorio, Rodrigo; Ashton, Gregory; Prix, Reinhard PyFstat: a Python package for continuous gravitational-wave data analysis Burns, Eric et al. Identification of a Local Sample of Gamma-Ray Bursts Consistent with a Magnetar Giant Flare Origin Ashton, Gregory; Lasky, Paul D.; Nathan, Rowina; Palfreyman, Jim Flickering of the Vela pulsar during its 2016 glitch Ashton, Gregory; Ackley, Kendall; Maga\u00f1a Hernandez, Ignacio; Piotrzkowski, Brandon Current observations are insufficient to confidently associate the binary black hole merger GW190521 with AGN J124942.3+344929 Xing-Jiang Zhu, Gregory Ashton Characterizing Astrophysical Binary Neutron Stars with Gravitational Waves Ashton, Gregory; Thrane, Eric The astrophysical odds of GW151216 Romero-Shaw, I. M.; Talbot, C.; Biscoveanu, S.; D'Emilio, V.; Ashton, G., et al. Bayesian inference for compact binary coalescences with BILBY: Validation and application to the first LIGO--Virgo gravitational-wave transient catalogue You, Zhi-Qiang; Zhu, Xing-Jiang; Ashton, Gregory; Thrane, Eric; Zhu, Zong-Hong Standard-siren cosmology using gravitational waves from binary black holes Sarin, Nikhil; Lasky, Paul D.; Ashton, Gregory Gravitational waves or deconfined quarks: what causes the premature collapse of neutron stars born in short gamma-ray bursts? Ashton, G.; Khan, S. Multi-waveform inference of gravitational waves Smith, Rory J. E.; Ashton, Gregory, Vajpeyi, Avi; Talbot, Colm Massively parallel Bayesian inference for transient gravitational-wave astronomy Ashton, Gregory; Thrane, Eric, Smith, Rory J. E. Gravitational wave detection without boot straps: a Bayesian approach Ashton, Gregory; Lasky, Paul D.; Graber, Vanessa; Palfreyman, Jim Rotational evolution of the Vela pulsar during the 2016 glitch Lasky, Paul D.; Sarin, Nikhil; Ashton, Greg Neutron Star Merger Remnants: Braking Indices, Gravitational Waves, and the Equation Of State Sarin, Nikhil; Lasky, Paul D.; Ashton, Greg X-ray afterglows of Short gamma-ray bursts: Magnetar or Fireball? Ashton, Gregory; Huebner, Moritz; Lasky, Paul D.; Talbot, Colm; et al. Bilby: A user-friendly Bayesian inference library for gravitational-wave astronomy Keitel, David; Ashton, Gregory Faster search for long gravitational-wave transients: GPU implementation of the transient F-statistic Ashton, Gregory; Prix, Reinhard; Jones, Ian A semicoherent glitch-robust continuous gravitational wave search N. Sarin, P.D. Lasky, L. Sammut, G. Ashton An X-ray guided gravitational-wave search for binary neutron star merger remnants (2018) G. Ashton, R. Prix, Hierarchical multi-stage MCMC follow-up of continuous gravitational wave candidates (2018) G. Ashton, D.I. Jones, and R. Prix Advances in our understanding of the free precession candidate PSR B1828-11 (2018) G. Ashton, E. Burns, T. Dal Canton, T. Dent, H.-B. Eggenstein, A. B. Nielsen, R. Prix, M. Was, S. J. Zhu Coincident detection significance in multimessenger astronomy G. Ashton, R. Prix, D. I. Jones Statistical characterization of pulsar glitches and their potential impact on searches for continuous gravitational waves D. I. Jones, G. Ashton G, R. Prix On the occurrence of glitches in pulsar free precession candidates G. Ashton, O. Birnholtz, M. Cabero, C. Capano, T. Dent, B. Krishnan, G. D. Meadors, A. B. Nielsen, A. Nitz, J. Westerweck Comments on: \"Echoes from the abyss: Evidence for Planck-scale structure at black hole horizons\" G. Ashton, D. I. Jones, R. Prix On the free-precession candidate PSR B1828-11: Evidence for increasing deformation G. Ashton PhD thesis: Timing variations in neutron stars: models, inference and their implications for gravitational waves A. Baker et al. Proposal of a micromagnetic standard problem for ferromagnetic resonance simulations (2016) G. Ashton, D. I. Jones, R. Prix Comparing models of the periodic variations in spin-down and beam-width for PSR B1828-11 (2016) G. Ashton, D. I. Jones, R. Prix The effect of timing noise on targeted and narrow-band coherent searches for continuous gravitational waves (2015) Workshops Apr/2021 Royal Hollaway's Astrophysics Residential Aug/2020 Parameter Estimation for Gravitational waves . Lead organizer, invited by the LIGOIndia community to train 60+ astrophysicists May/2020 LIGO-Virgo Collaboration GW Open Data Workshop #3 . Co-organizer, invited to write and coordinate the Parameter Estimation tutorials for 100 students (virtual). Nov/2018 OzGrav workshop: Towards O3. Lead organizer, 20 participants from the OzGrav inference program. A software development sprint. July/2018 OzGrav workshop: Introduction to Inference . Lead organiser, 33 international participants. Training in Bayesian inference and software development. Identifying new projects across the OzGrav nodes and themes.. Miscellaneous Nature Astronomy Community, Behind the Paper: Understanding the rotational evolution of the Vela pulsar during the 2016 glitch Institute of Physics, Gravitational Physics Group 2015 newsletter M. Franchin et al. Current driven nucleation of domain walls in cylindrical nanowires (2011) Selected Presentations Journal club at CAMK in which I presented Flickering of the Vela pulsar . Seminar at Bar-Ilan University, Israel, January 2021: The deepening mystery of the Vela radio-pulsar glitch GR22/Amaldi13 meeting, Valencia, Spain, July 2019: Gravitational Wave Detection: A Fully Bayesian Approach (contributed) IPTA annual meeting, Pune, India, June 2019: Internal neutron-star physics from the 2016 Vela glitch (contributed, remote) Astrophysics Colloquium, University of Melbourne, October 2018: Astrophysical inference and transient gravitational wave astronomy (invited) ASA Annual Scientific Meeting, Melbourne, Australia, June 2018: Multimessenger follow-up of continuous gravitational wave candidates (contributed) Australasian pulsar meeting, September 2018: Periodic modulations and a glitch in PSR B1828-11 (remote) Institute for Nuclear Theory Workshop INT-18-71W, Astro-Solids, Dense Matter, and Gravitational Waves (April 16 - 20, 2018): Continuous wave parameter estimation and non-standard signal follow up (invited) 11th Bonn workshop on Formation and Evolution of Neutron Stars, Bonn, Germany, December 2017: Neutron stars as continuous gravitational wave emitters Annual NewCompStar Conference , Istanbul, Turkey, 2016: Learning about neutron stars from pulsar precession observations (contributed, best student talk prize) Annual NewCompStar Conference , Budapest, Hungary 2015: Comparing different models of pulsar timing noise (contributed) BritGrav , Birmingham, UK, 2015: Applying Bayesian data analysis to learn about periodic variability in pulsars (contributed) BritGrav , Cambridge, UK, 2014: Gravitational wave searches from noisy neutron stars (contributed, runner up prize for best talk by IoP) Press Interview on Adelaide FiveAA to discuss GW190425, the second binary neutron star event observed by LIGO & Virgo Press for Nature Astronomy article \"Rotational evolution of the Vela pulsar during the 2016 glitch\": The Age: Patient astronomers crack the code of super-dense spinning stars CNET: Astronomers watched a neutron star 'glitch' and can't yet explain it The Register: Mysterious 'glitch' in neutron stars may be down to an itch under the body's surface ABC \"Your Afternoon\" Helen Shield interviews my excellent co-author Jim Palfreyman Phys.org Glitch in neutron star reveals its hidden secrets Astronomy: Astronomers catch a pulsar 'glitching,' offering insights into the strange stars Forbes: A Radio Glitch Reveals The Structure Of A Neutron Star Advocator: Neutron Star Anomaly Revealed More Details On These Mysterious Space Objects ZME Science: Peculiar pulsar slows down before \u2018glitching\u2019 Futarism: A NEUTRON STAR \u201cGLITCHED\u201d \u2014 AND SCIENTISTS NOTICED SOMETHING AMAZING Sci-News: Glitch in Vela Pulsar Provides Unique Opportunity to Study Neutron Star\u2019s Interior Science Daily: Glitch in neutron star reveals its hidden secrets Space.com: Weird Star Slows Down Before 'Glitching,' and No One Knows Why Science Alert: Astronomers Just Got Closer to Unravelling The Mystery of 'Glitching' Pulsars Live Science: Maybe Neutron Stars 'Glitch Out' So Much Because They're Full of Soup IFLS: A Glitch In A Neutron Star Allowed Astronomers To \"Peek\" At Its Interior Spektrum: Wenn Neutronensterne aus dem Takt geraten Physics World: Pulsar glitch suggests superfluid layers lie within neutron star SciShow News: August 16 update","title":"Science"},{"location":"science/#science","text":"","title":"Science"},{"location":"science/#publications","text":"I maintain an ADS library of my publications in addition to the following list. Vajpeyi, Avi, et al A search for intermediate-mass black holes mergers in the second LIGO--Virgo observing run with the Bayes Coherence Ratio Ashton, Gregory; Talbot, Colm Bilby-MCMC: An MCMC sampler for gravitational-wave inference Keitel, David; Tenorio, Rodrigo; Ashton, Gregory; Prix, Reinhard PyFstat: a Python package for continuous gravitational-wave data analysis Burns, Eric et al. Identification of a Local Sample of Gamma-Ray Bursts Consistent with a Magnetar Giant Flare Origin Ashton, Gregory; Lasky, Paul D.; Nathan, Rowina; Palfreyman, Jim Flickering of the Vela pulsar during its 2016 glitch Ashton, Gregory; Ackley, Kendall; Maga\u00f1a Hernandez, Ignacio; Piotrzkowski, Brandon Current observations are insufficient to confidently associate the binary black hole merger GW190521 with AGN J124942.3+344929 Xing-Jiang Zhu, Gregory Ashton Characterizing Astrophysical Binary Neutron Stars with Gravitational Waves Ashton, Gregory; Thrane, Eric The astrophysical odds of GW151216 Romero-Shaw, I. M.; Talbot, C.; Biscoveanu, S.; D'Emilio, V.; Ashton, G., et al. Bayesian inference for compact binary coalescences with BILBY: Validation and application to the first LIGO--Virgo gravitational-wave transient catalogue You, Zhi-Qiang; Zhu, Xing-Jiang; Ashton, Gregory; Thrane, Eric; Zhu, Zong-Hong Standard-siren cosmology using gravitational waves from binary black holes Sarin, Nikhil; Lasky, Paul D.; Ashton, Gregory Gravitational waves or deconfined quarks: what causes the premature collapse of neutron stars born in short gamma-ray bursts? Ashton, G.; Khan, S. Multi-waveform inference of gravitational waves Smith, Rory J. E.; Ashton, Gregory, Vajpeyi, Avi; Talbot, Colm Massively parallel Bayesian inference for transient gravitational-wave astronomy Ashton, Gregory; Thrane, Eric, Smith, Rory J. E. Gravitational wave detection without boot straps: a Bayesian approach Ashton, Gregory; Lasky, Paul D.; Graber, Vanessa; Palfreyman, Jim Rotational evolution of the Vela pulsar during the 2016 glitch Lasky, Paul D.; Sarin, Nikhil; Ashton, Greg Neutron Star Merger Remnants: Braking Indices, Gravitational Waves, and the Equation Of State Sarin, Nikhil; Lasky, Paul D.; Ashton, Greg X-ray afterglows of Short gamma-ray bursts: Magnetar or Fireball? Ashton, Gregory; Huebner, Moritz; Lasky, Paul D.; Talbot, Colm; et al. Bilby: A user-friendly Bayesian inference library for gravitational-wave astronomy Keitel, David; Ashton, Gregory Faster search for long gravitational-wave transients: GPU implementation of the transient F-statistic Ashton, Gregory; Prix, Reinhard; Jones, Ian A semicoherent glitch-robust continuous gravitational wave search N. Sarin, P.D. Lasky, L. Sammut, G. Ashton An X-ray guided gravitational-wave search for binary neutron star merger remnants (2018) G. Ashton, R. Prix, Hierarchical multi-stage MCMC follow-up of continuous gravitational wave candidates (2018) G. Ashton, D.I. Jones, and R. Prix Advances in our understanding of the free precession candidate PSR B1828-11 (2018) G. Ashton, E. Burns, T. Dal Canton, T. Dent, H.-B. Eggenstein, A. B. Nielsen, R. Prix, M. Was, S. J. Zhu Coincident detection significance in multimessenger astronomy G. Ashton, R. Prix, D. I. Jones Statistical characterization of pulsar glitches and their potential impact on searches for continuous gravitational waves D. I. Jones, G. Ashton G, R. Prix On the occurrence of glitches in pulsar free precession candidates G. Ashton, O. Birnholtz, M. Cabero, C. Capano, T. Dent, B. Krishnan, G. D. Meadors, A. B. Nielsen, A. Nitz, J. Westerweck Comments on: \"Echoes from the abyss: Evidence for Planck-scale structure at black hole horizons\" G. Ashton, D. I. Jones, R. Prix On the free-precession candidate PSR B1828-11: Evidence for increasing deformation G. Ashton PhD thesis: Timing variations in neutron stars: models, inference and their implications for gravitational waves A. Baker et al. Proposal of a micromagnetic standard problem for ferromagnetic resonance simulations (2016) G. Ashton, D. I. Jones, R. Prix Comparing models of the periodic variations in spin-down and beam-width for PSR B1828-11 (2016) G. Ashton, D. I. Jones, R. Prix The effect of timing noise on targeted and narrow-band coherent searches for continuous gravitational waves (2015)","title":"Publications"},{"location":"science/#workshops","text":"Apr/2021 Royal Hollaway's Astrophysics Residential Aug/2020 Parameter Estimation for Gravitational waves . Lead organizer, invited by the LIGOIndia community to train 60+ astrophysicists May/2020 LIGO-Virgo Collaboration GW Open Data Workshop #3 . Co-organizer, invited to write and coordinate the Parameter Estimation tutorials for 100 students (virtual). Nov/2018 OzGrav workshop: Towards O3. Lead organizer, 20 participants from the OzGrav inference program. A software development sprint. July/2018 OzGrav workshop: Introduction to Inference . Lead organiser, 33 international participants. Training in Bayesian inference and software development. Identifying new projects across the OzGrav nodes and themes..","title":"Workshops"},{"location":"science/#miscellaneous","text":"Nature Astronomy Community, Behind the Paper: Understanding the rotational evolution of the Vela pulsar during the 2016 glitch Institute of Physics, Gravitational Physics Group 2015 newsletter M. Franchin et al. Current driven nucleation of domain walls in cylindrical nanowires (2011)","title":"Miscellaneous"},{"location":"science/#selected-presentations","text":"Journal club at CAMK in which I presented Flickering of the Vela pulsar . Seminar at Bar-Ilan University, Israel, January 2021: The deepening mystery of the Vela radio-pulsar glitch GR22/Amaldi13 meeting, Valencia, Spain, July 2019: Gravitational Wave Detection: A Fully Bayesian Approach (contributed) IPTA annual meeting, Pune, India, June 2019: Internal neutron-star physics from the 2016 Vela glitch (contributed, remote) Astrophysics Colloquium, University of Melbourne, October 2018: Astrophysical inference and transient gravitational wave astronomy (invited) ASA Annual Scientific Meeting, Melbourne, Australia, June 2018: Multimessenger follow-up of continuous gravitational wave candidates (contributed) Australasian pulsar meeting, September 2018: Periodic modulations and a glitch in PSR B1828-11 (remote) Institute for Nuclear Theory Workshop INT-18-71W, Astro-Solids, Dense Matter, and Gravitational Waves (April 16 - 20, 2018): Continuous wave parameter estimation and non-standard signal follow up (invited) 11th Bonn workshop on Formation and Evolution of Neutron Stars, Bonn, Germany, December 2017: Neutron stars as continuous gravitational wave emitters Annual NewCompStar Conference , Istanbul, Turkey, 2016: Learning about neutron stars from pulsar precession observations (contributed, best student talk prize) Annual NewCompStar Conference , Budapest, Hungary 2015: Comparing different models of pulsar timing noise (contributed) BritGrav , Birmingham, UK, 2015: Applying Bayesian data analysis to learn about periodic variability in pulsars (contributed) BritGrav , Cambridge, UK, 2014: Gravitational wave searches from noisy neutron stars (contributed, runner up prize for best talk by IoP)","title":"Selected Presentations"},{"location":"science/#press","text":"Interview on Adelaide FiveAA to discuss GW190425, the second binary neutron star event observed by LIGO & Virgo Press for Nature Astronomy article \"Rotational evolution of the Vela pulsar during the 2016 glitch\": The Age: Patient astronomers crack the code of super-dense spinning stars CNET: Astronomers watched a neutron star 'glitch' and can't yet explain it The Register: Mysterious 'glitch' in neutron stars may be down to an itch under the body's surface ABC \"Your Afternoon\" Helen Shield interviews my excellent co-author Jim Palfreyman Phys.org Glitch in neutron star reveals its hidden secrets Astronomy: Astronomers catch a pulsar 'glitching,' offering insights into the strange stars Forbes: A Radio Glitch Reveals The Structure Of A Neutron Star Advocator: Neutron Star Anomaly Revealed More Details On These Mysterious Space Objects ZME Science: Peculiar pulsar slows down before \u2018glitching\u2019 Futarism: A NEUTRON STAR \u201cGLITCHED\u201d \u2014 AND SCIENTISTS NOTICED SOMETHING AMAZING Sci-News: Glitch in Vela Pulsar Provides Unique Opportunity to Study Neutron Star\u2019s Interior Science Daily: Glitch in neutron star reveals its hidden secrets Space.com: Weird Star Slows Down Before 'Glitching,' and No One Knows Why Science Alert: Astronomers Just Got Closer to Unravelling The Mystery of 'Glitching' Pulsars Live Science: Maybe Neutron Stars 'Glitch Out' So Much Because They're Full of Soup IFLS: A Glitch In A Neutron Star Allowed Astronomers To \"Peek\" At Its Interior Spektrum: Wenn Neutronensterne aus dem Takt geraten Physics World: Pulsar glitch suggests superfluid layers lie within neutron star SciShow News: August 16 update","title":"Press"},{"location":"notes/splitting_up_mrs/","text":"Splitting up a large Merge Request It is common when developing a new feature on a branch to end up fixing a number of bugs or extending functionality elsewhere in the code. After you are done, however, the code reviewers may well ask that the bug fixes be separated into a separate merge request. This makes their life easier. They can review the bug fixes and get these merges into master quickly. Meanwhile, your new feature may need a more in-depth review. It would not be sensible to hold up fixing bugs based on the review of new code. In this note, I'll describe the method I use to break such large merge requests up. Advice on merge requests in general can be found here . Figure out where the changes are Let's say you are developing on feature-branch and want to merge into main-branch . First, let's figure out which files have been modified: $ git diff --name-only main-branch feature-branch src/utils.py src/magic.py Here we can see that both utils.py and magic.py have been modified. Let's say that the changes to utils.py where all bug fixes while magic.py is a new file introducing new features. The code reviewers want to split up our merge request into two: one which only adds the bug fixes to utils.py and a second one which adds the new functionality in magic.py . The Problem and Solution The problem, from our perspective, is that the changes to magic.py depend on the changes to utils.py ! Of course, we fixed the bugs so that it would run. To satisfy the code reviewers while not breaking our branch, we need to: Create a new merge request with only the changes to utils.py included Request the new merge request be merged into master Rebase our feature-branch to master (bringing with it the changes to utils.py ) Now we have a feature-branch with only magic.py being changed, but all the while feature-branch never got broken. Technical how-to The steps above can be done as follows: Create a new merge request with only the changes to utils.py included $ (main-branch) git checkout main-branch $ (main-branch) git checkout -b fix-utils # Create branch of main-branch $ (fix-utils) git diff main-branch feature-branch -- src/utils.py > utils_changes.patch # Write the diff between the main and feature branches to a patch $ (fix-utils) git apply utils_changes.patch # Apply the patch $ (fix-utils) git commit -m \"Fixing utils\" Now you can push this branch and create a merge request. Once fix-utils gets merged into main-branch , all you need to do is rebase your feature-branch to main-branch and then your merge request will only contain changes to magic.py . Magic.","title":"Splitting up a large Merge Request"},{"location":"notes/splitting_up_mrs/#splitting-up-a-large-merge-request","text":"It is common when developing a new feature on a branch to end up fixing a number of bugs or extending functionality elsewhere in the code. After you are done, however, the code reviewers may well ask that the bug fixes be separated into a separate merge request. This makes their life easier. They can review the bug fixes and get these merges into master quickly. Meanwhile, your new feature may need a more in-depth review. It would not be sensible to hold up fixing bugs based on the review of new code. In this note, I'll describe the method I use to break such large merge requests up. Advice on merge requests in general can be found here .","title":"Splitting up a large Merge Request"},{"location":"notes/splitting_up_mrs/#figure-out-where-the-changes-are","text":"Let's say you are developing on feature-branch and want to merge into main-branch . First, let's figure out which files have been modified: $ git diff --name-only main-branch feature-branch src/utils.py src/magic.py Here we can see that both utils.py and magic.py have been modified. Let's say that the changes to utils.py where all bug fixes while magic.py is a new file introducing new features. The code reviewers want to split up our merge request into two: one which only adds the bug fixes to utils.py and a second one which adds the new functionality in magic.py .","title":"Figure out where the changes are"},{"location":"notes/splitting_up_mrs/#the-problem-and-solution","text":"The problem, from our perspective, is that the changes to magic.py depend on the changes to utils.py ! Of course, we fixed the bugs so that it would run. To satisfy the code reviewers while not breaking our branch, we need to: Create a new merge request with only the changes to utils.py included Request the new merge request be merged into master Rebase our feature-branch to master (bringing with it the changes to utils.py ) Now we have a feature-branch with only magic.py being changed, but all the while feature-branch never got broken.","title":"The Problem and Solution"},{"location":"notes/splitting_up_mrs/#technical-how-to","text":"The steps above can be done as follows: Create a new merge request with only the changes to utils.py included $ (main-branch) git checkout main-branch $ (main-branch) git checkout -b fix-utils # Create branch of main-branch $ (fix-utils) git diff main-branch feature-branch -- src/utils.py > utils_changes.patch # Write the diff between the main and feature branches to a patch $ (fix-utils) git apply utils_changes.patch # Apply the patch $ (fix-utils) git commit -m \"Fixing utils\" Now you can push this branch and create a merge request. Once fix-utils gets merged into main-branch , all you need to do is rebase your feature-branch to main-branch and then your merge request will only contain changes to magic.py . Magic.","title":"Technical how-to"},{"location":"old_notes/importance_reweighting_example/","text":"Importance reweighting example \"\"\" Script to test importance reweighting In this script we generate data according to y = m x + c + Normal(0, sigma) Then 1) Calculate the \"full\" posterior P(m, c | data) 2) Calculate the \"partial\" posterior P(m | data, c=0) (note c=0 in the injection) 3) Use importance reweighting to calculate P(m| data) from the \"partial\" results \"\"\" import matplotlib.pyplot as plt import numpy as np import bilby from scipy.special import logsumexp import tqdm np . random . seed ( 1234 ) outdir = '.' sampler = 'dynesty' npoints = 5000 def marginalized_log_likelihood_over_c ( m , likelihood ): \"\"\" Calculates L(data| m), marginalized over c Parameters ---------- m: float The fixed value of m at which to calculate the marginalized likelihood likelihood: bilby.core.likelihood.Likelihood instance Used to evaluate the log likelihood Note ---- Integration range chosen to cover the region of interest. Note, this neglects the normalization factors which don't count in the weight calculation. \"\"\" likelihood . parameters [ 'm' ] = m c_array = np . linspace ( - 0.2 , 0.2 , 100 ) integrand = [] for c in c_array : likelihood . parameters [ 'c' ] = c integrand . append ( likelihood . log_likelihood ()) return logsumexp ( integrand ) def model ( x , m , c ): return m * x + c # Injection parameters and create data m = 1 c = 0 sigma = 0.1 N = 100 x = np . linspace ( 0 , 1 , N ) y = model ( x , m , c ) + np . random . normal ( 0 , sigma , N ) likelihood = bilby . core . likelihood . GaussianLikelihood ( x , y , model ) # Run the full PE priors = dict () priors [ 'm' ] = bilby . core . prior . Uniform ( 0 , 5 , 'm' ) priors [ 'c' ] = bilby . core . prior . Uniform ( - 2 , 2 , 'c' ) priors [ 'sigma' ] = sigma full_result = bilby . run_sampler ( likelihood = likelihood , priors = priors , sampler = sampler , npoints = npoints , outdir = outdir , label = 'full' ) full_result . plot_corner () # Run the constrained PE priors = dict () priors [ 'm' ] = bilby . core . prior . Uniform ( 0 , 5 , 'm' ) priors [ 'c' ] = 0 priors [ 'sigma' ] = sigma partial_result = bilby . run_sampler ( likelihood = likelihood , priors = priors , sampler = sampler , npoints = npoints , outdir = outdir , label = 'partial' ) partial_result . plot_corner () # Pull out the uniformly-weighted samples from the full and partial runs full_m_samples = full_result . posterior . m . values partial_m_samples = partial_result . posterior . m . values # Calculate primed likelihood log_likelihood_prime = [] for m in tqdm . tqdm ( partial_m_samples ): log_likelihood_prime . append ( marginalized_log_likelihood_over_c ( m , likelihood )) log_likelihood_prime = np . array ( log_likelihood_prime ) # Calculate p, the normalized probably for each sample in partial_m_samples log_likelihood = partial_result . posterior . log_likelihood . values weights = log_likelihood_prime - log_likelihood p = np . exp ( weights ) p /= np . sum ( p ) # Reweight to get corrected samples reweight_samples = np . random . choice ( partial_m_samples , size = 30000 , p = p ) # Plot bins = np . linspace ( 0.9 , 1.1 , 50 ) fig , ax = plt . subplots () ax . hist ( full_m_samples , bins = bins , density = True , label = \"full\" , histtype = 'step' , linewidth = 2.5 ) ax . hist ( partial_m_samples , bins = bins , density = True , alpha = 0.5 , label = \"partial\" ) ax . hist ( reweight_samples , bins = bins , density = True , alpha = 0.5 , label = \"resampled\" ) ax . legend () ax . set_xlabel ( \"m\" ) plt . savefig ( \"posterior\" ) Having run this script, we obtain three images. First, the full posterior Second, the posterior when fixing c=0 Finally, the rewighted posterior from fixed case","title":"Importance reweighting example"},{"location":"old_notes/importance_reweighting_example/#importance-reweighting-example","text":"\"\"\" Script to test importance reweighting In this script we generate data according to y = m x + c + Normal(0, sigma) Then 1) Calculate the \"full\" posterior P(m, c | data) 2) Calculate the \"partial\" posterior P(m | data, c=0) (note c=0 in the injection) 3) Use importance reweighting to calculate P(m| data) from the \"partial\" results \"\"\" import matplotlib.pyplot as plt import numpy as np import bilby from scipy.special import logsumexp import tqdm np . random . seed ( 1234 ) outdir = '.' sampler = 'dynesty' npoints = 5000 def marginalized_log_likelihood_over_c ( m , likelihood ): \"\"\" Calculates L(data| m), marginalized over c Parameters ---------- m: float The fixed value of m at which to calculate the marginalized likelihood likelihood: bilby.core.likelihood.Likelihood instance Used to evaluate the log likelihood Note ---- Integration range chosen to cover the region of interest. Note, this neglects the normalization factors which don't count in the weight calculation. \"\"\" likelihood . parameters [ 'm' ] = m c_array = np . linspace ( - 0.2 , 0.2 , 100 ) integrand = [] for c in c_array : likelihood . parameters [ 'c' ] = c integrand . append ( likelihood . log_likelihood ()) return logsumexp ( integrand ) def model ( x , m , c ): return m * x + c # Injection parameters and create data m = 1 c = 0 sigma = 0.1 N = 100 x = np . linspace ( 0 , 1 , N ) y = model ( x , m , c ) + np . random . normal ( 0 , sigma , N ) likelihood = bilby . core . likelihood . GaussianLikelihood ( x , y , model ) # Run the full PE priors = dict () priors [ 'm' ] = bilby . core . prior . Uniform ( 0 , 5 , 'm' ) priors [ 'c' ] = bilby . core . prior . Uniform ( - 2 , 2 , 'c' ) priors [ 'sigma' ] = sigma full_result = bilby . run_sampler ( likelihood = likelihood , priors = priors , sampler = sampler , npoints = npoints , outdir = outdir , label = 'full' ) full_result . plot_corner () # Run the constrained PE priors = dict () priors [ 'm' ] = bilby . core . prior . Uniform ( 0 , 5 , 'm' ) priors [ 'c' ] = 0 priors [ 'sigma' ] = sigma partial_result = bilby . run_sampler ( likelihood = likelihood , priors = priors , sampler = sampler , npoints = npoints , outdir = outdir , label = 'partial' ) partial_result . plot_corner () # Pull out the uniformly-weighted samples from the full and partial runs full_m_samples = full_result . posterior . m . values partial_m_samples = partial_result . posterior . m . values # Calculate primed likelihood log_likelihood_prime = [] for m in tqdm . tqdm ( partial_m_samples ): log_likelihood_prime . append ( marginalized_log_likelihood_over_c ( m , likelihood )) log_likelihood_prime = np . array ( log_likelihood_prime ) # Calculate p, the normalized probably for each sample in partial_m_samples log_likelihood = partial_result . posterior . log_likelihood . values weights = log_likelihood_prime - log_likelihood p = np . exp ( weights ) p /= np . sum ( p ) # Reweight to get corrected samples reweight_samples = np . random . choice ( partial_m_samples , size = 30000 , p = p ) # Plot bins = np . linspace ( 0.9 , 1.1 , 50 ) fig , ax = plt . subplots () ax . hist ( full_m_samples , bins = bins , density = True , label = \"full\" , histtype = 'step' , linewidth = 2.5 ) ax . hist ( partial_m_samples , bins = bins , density = True , alpha = 0.5 , label = \"partial\" ) ax . hist ( reweight_samples , bins = bins , density = True , alpha = 0.5 , label = \"resampled\" ) ax . legend () ax . set_xlabel ( \"m\" ) plt . savefig ( \"posterior\" ) Having run this script, we obtain three images. First, the full posterior Second, the posterior when fixing c=0 Finally, the rewighted posterior from fixed case","title":"Importance reweighting example"}]}